,abstract,authors,doi,keywords,title
0,"Fog computing emerged as a new computing paradigm which moves the computing power to the proximity of users, from core to the edge of the network. It is known as the extension of Cloud computing and it offers inordinate opportunities for real-time and latency-sensitive IoT applications. An IoT application consists of a set of dependent Processing Elements (PEs) defined as operations performed on data streams and can be modeled as a Directed Acyclic Graph (DAG). Each PE performs a variety of low-level computation on the incoming data such as aggregation or filtering. A key challenge is to decide how to distribute such PEs over the resources, in order to minimize the overall response time of the entire PE graph. This problem is known as distributed PE scheduling and placement problem. In this work, we try to address the question of how fog computing paradigm can help reducing the IoT application response time by efficiently distributing PE graphs over the Fog-Cloud continuum. We mathematically formulate the fundamental characteristics of IoT application and Fog infrastructure, then model the system as an optimization problem using Gravitational Search Algorithm (GSA) meta-heuristic technique. Our proposed GSA model is evaluated by comparing it with a well-known evolutionary algorithm in the literature via simulation. Also, a comparative analysis with the legacy cloud infrastructure is done in order to show the significant impact of fog presence on the performance of PE processing. Evaluation of our model demonstrates the efficiency of our approach comparing to the current literature.","Amir Karamoozian, Abdelhakim Hafid, El Mostapha Aboulhamid",http://dx.doi.org/10.1109/fmec.2019.8795320,"Internet of Things, IoT stream processing, Fog/Cloud Computing, Scheduling and Placement optimization",On the Fog-Cloud Cooperation: How Fog Computing can address latency concerns of IoT applications
1,"Video streaming is growing in popularity and has become the most bandwidth-consuming Internet service. As such, robust streaming in terms of low latency and uninterrupted streaming experience, particularly for viewers in distant areas, has become a challenge. The common practice to reduce latency is to pre-process multiple versions of each video and use Content Delivery Networks (CDN) to cache videos that are popular in a geographical area. However, with the fast-growing video repository sizes, caching video contents in multiple versions on each CDN is becoming inefficient. Accordingly, in this paper, we propose the architecture for Fog Delivery Networks (FDN) and provide methods to federate them (called F-FDN) to reduce video streaming latency. In addition to caching, FDNs have the ability to process videos in an on-demand manner. F-FDN leverages cached contents on the neighboring FDNs to further reduce latency. In particular, F-FDN is equipped with methods that aim at reducing latency through probabilistically evaluating the cost benefit of fetching video segments either from neighboring FDNs or by processing them. Experimental results against alternative streaming methods show that both on-demand processing and leveraging cached video segments on neighboring FDNs can remarkably reduce streaming latency (on average 52%).","Vaughan Veillon, Chavit Denninnart, Mohsen Amini Salehi",http://dx.doi.org/10.1109/cfec.2019.8733154,,F-FDN: Federation of Fog Computing Systems for Low Latency Video Streaming
2,"In this paper, the fundamental problem of distribution and proactive caching of computing tasks in fog networks is studied under latency and reliability constraints. In the proposed scenario, computing can be executed either locally at the user device or offloaded to an edge cloudlet. Moreover, cloudlets exploit both their computing and storage capabilities by proactively caching popular task computation results to minimize computing latency. To this end, a clustering method to group spatially proximate user devices with mutual task popularity interests and their serving cloudlets is proposed. Then, cloudlets can proactively cache the popular tasks' computations of their cluster members to minimize computing latency. Additionally, the problem of distributing tasks to cloudlets is formulated as a matching game in which a cost function of computing delay is minimized under latency and reliability constraints. Simulation results show that the proposed scheme guarantees reliable computations with bounded latency and achieves up to 91% decrease in computing latency as compared to baseline schemes.","Mohammed S. Elbamby, Mehdi Bennis, Walid Saad",http://dx.doi.org/10.1109/eucnc.2017.7980678,,Proactive edge computing in latency-constrained fog networks
3,"Fog computing has the potential to be an energy-efficient alternative to cloud computing for guaranteeing latency requirements of Latency-critical (LC) IoT services. However, even in fog computing low energy-efficiency of homogeneous multi-core server processors can be a major contributor to energy wastage. Recent studies have shown that Heterogeneous Multi-core Processors (HMPs) can improve energy efficiency of servers by adapting to dynamic load changes of LC-services. However, proposed approaches optimize energy only at a single server level. In our work, we demonstrate that optimization at the cluster-level across many HMP-servers can offer much greater energy savings through optimal work distribution across the HMP-servers while still guaranteeing the Service Level Objectives (SLO) of LC-services. In this paper, we present Greeniac, a cluster-level task manager that employs Reinforcement Learning to identify optimal configurations at the server- and cluster-levels for different workloads. We develop a server-level service scheduler and a cluster-level load balancing module to assign services and distribute tasks across HMP servers based on the learned configurations. In addition to meeting the required SLO targets, Greeniac achieves up to 28% energy saving compared to best-case cluster scheduling techniques with local HMP-aware scheduling on a 4-server fog cluster, with potentially larger savings in a larger cluster.","Sambit Shukla, Dipak Ghosal, Kesheng Wu, Alex Sim, Matthew Farrens",http://dx.doi.org/10.1109/fmec.2019.8795353,,Co-optimizing Latency and Energy for IoT services using HMP servers in Fog Clusters
4,"Traditional cloud-based infrastructures are not enough for the current demands of Internet of Things (IoT) applications. Two major issues are the limitations in terms of latency and network bandwidth. In recent years, the concepts of fog computing and edge computing were proposed to alleviate these limitations by moving data processing capabilities closer to the network edge. Considering IoT growth and development forecasts, we believe the full potential of IoT can, in many cases, only be unlocked by combining cloud, fog and edge computing. This paper discusses four possible approaches for distributing workload among these levels. We also highlight developments and possibilities as well as consider challenges for implementation in the areas of hardware, machine learning, security, privacy and communication.","Kay Bierzynski, Antonio Escobar, Matthias Eberl",http://dx.doi.org/10.1109/fmec.2017.7946409,"Internet of Things, Cloud Computing, Fog Computing, Edge Computing, Machine Learning, Network Security, Hardware","Cloud, fog and edge: Cooperation for the future?"
5,"When it comes to storage and computation of large scales of data, Cloud Computing has acted as the de-facto solution over the past decade. However, with the massive growth in intelligent and mobile devices coupled with technologies like Internet of Things (IoT), V2X Communications, Augmented Reality (AR), the focus has shifted towards gaining real-time responses along with support for context-awareness and mobility. Due to the delays induced on the Wide Area Network (WAN) and location agnostic provisioning of resources on the cloud, there is a need to bring the features of the cloud closer to the consumer devices. This led to the birth of the Edge Computing paradigm which aims to provide context aware storage and distributed Computing at the edge of the networks. In this paper, we discuss the three different implementations of Edge Computing namely Fog Computing, Cloudlet and Mobile Edge Computing in detail and compare their features. We define a set of parameters based on which one of these implementations can be chosen optimally given a particular use-case or application and present a decision tree for the selection of the optimal implementation.","Koustabh Dolui, Soumya Kanti Datta",http://dx.doi.org/10.1109/giots.2017.8016213,"Cloud Computing, Cloudlet, Edge Computing, Fog Computing, IoT, Mobile Edge Computing","Comparison of edge computing implementations: Fog computing, cloudlet and mobile edge computing"
6,"Cloud computing has established itself as an alternative IT infrastructure and service model. However, as with all logically centralized resource and service provisioning infrastructures, cloud does not handle well local issues involving a large number of networked elements (IoTs) and it is not responsive enough for many applications that require immediate attention of a local controller. Fog computing preserves many benefits of cloud computing and it is also in a good position to address these local and performance issues because its resources and specific services are virtualized and located at the edge of the customer premise. However, data security is a critical challenge in fog computing especially when fog nodes and their data move frequently in its environment. This paper addresses the data protection and the performance issues by 1) proposing a Region-Based Trust-Aware (RBTA) model for trust translation among fog nodes of regions, 2) introducing a Fog-based Privacy-aware Role Based Access Control (FPRBAC) for access control at fog nodes, and 3) developing a mobility management service to handle changes of users and fog devices' locations. The implementation results demonstrate the feasibility and the efficiency of our proposed framework.","Thanh Dat Dang, Doan Hoang",http://dx.doi.org/10.1109/fmec.2017.7946404,"fog computing, cloud computing, data protection, mobility, fog security, fog location, access control",A data protection model for fog computing
7,"The Internet of Things (IoT) has been one of the key disruptive technologies over the last few years, with its promise of optimizing and automating current manual tasks and evolving existing services. From the security perspective, the increasing adoption of IoT devices in all aspects of our society has exposed businesses and consumers to a number of threats, such as Distributed Denial of Service (DDoS) attacks. To tackle this IoT security problem, we proposed AntibIoTic 1.0 [1]. However, this solution has some limitations that make it difficult (when not impossible) to be implemented in a legal and controlled manner. Along the way, Fog computing was born: a novel paradigm that aims at bridging the gap between IoT and Cloud computing, providing a number of benefits, including security. As a result, in this paper, we present AntibIoTic 2.0, an anti-malware that relies upon Fog computing to secure IoT devices and to overcome the main issues of its predecessor (AntibIoTic 1.0). First, we present AntibIoTic 1.0 and its main problem. Then, after introducing Fog computing, we present AntibIoTic 2.0, showing how it overcomes the main issues of its predecessor by including Fog computing in its design.","Michele De Donno, Nicola Dragoni",http://dx.doi.org/10.1109/cfec.2019.8733144,"Fog Computing, Internet of Things, Security, Distributed Denial of Service, Malware, Anti-Malware",Combining AntibIoTic with Fog Computing: AntibIoTic 2.0
8,"Fog computing is the answer to the emerging need of mobility support, mostly due to the deployment of the Internet of Things. In this paper, motivated by the many security and privacy issues found in handling device's handover in Fog computing, we propose a new approach based on the possibilities offered by the recent EU regulation eIDAS, for improving the security in the identification of users, when they require data mobility.","Franscesco Buccafurri, Gianluca Lax, Antonia Russo",http://dx.doi.org/10.1109/fmec.2019.8795342,"Authentication, eIDAS, eID Scheme, IoT",Exploiting Digital Identity for Mobility in Fog Computing
9,"The present paper outlines the framework design of an Application Agnostic Architecture for Fog and Mist Computing systems. An analysis explains how the proposed architecture satisfies the primary characteristics of a Fog and Mist computing paradigm by using low power and low-cost components. It also introduces an Indoor Navigation System and a Notification service as a use-case, to assess the proposed framework as a Fog-Computing architecture while demonstrating how it can address Mobile and IoT challenges.","Pietro Battistoni, Monica Sebillo, Giuliana Vitiello",http://dx.doi.org/10.1109/fmec.2019.8795307,"Fog Computing, Mist Computing, Edge Computing, MQTT, Indoor Navigation System, ESP32",Experimenting with a Fog-computing Architecture for Indoor Navigation
10,"Internet of Things (IoT) has accelerated the deployment of millions of sensors at the edge of the network, through Smart City infrastructure and lifestyle devices. Cloud computing platforms are often tasked with handling these large volumes and fast streams of data from the edge. Recently, Fog computing has emerged as a concept for low-latency and resource-rich processing of these observation streams, to complement Edge and Cloud computing. In this paper, we review various dimensions of system architecture, application characteristics and platform abstractions that are manifest in this Edge, Fog and Cloud eco-system. We highlight novel capabilities of the Edge and Fog layers, such as physical and application mobility, privacy sensitivity, and a nascent runtime environment. IoT application case studies based on first-hand experiences across diverse domains drive this categorization. We also highlight the gap between the potential and the reality of Fog computing, and identify challenges that need to be overcome for the solution to be sustainable. Taken together, our article can help platform and application developers bridge the gap that remains in making Fog computing viable.","Prateeksha Varshney, Yogesh Simmhan",http://dx.doi.org/10.1109/icfec.2017.20,,"Demystifying Fog Computing: Characterizing Architectures, Applications and Abstractions"
11,"The prevalence of Internet of Things (IoT) in contemporary settings has induced systems composed of heterogeneous devices, computing infrastructures, and cloud services. New paradigms have emerged where computational resources are managed closer to IoT end-devices, within a general theme of decoupling from the cloud. This is because meeting application demands must occur at runtime, in the face of uncertainty and in a decentralized manner. Taking advantage of available resources closer to devices calls for novel resource allocation techniques that comply with latency, privacy and decentralization demands of IoT applications. To this end, we propose a novel decentralized resource management technique and accompanying technical framework for the deployment of latency-sensitive IoT applications on edge devices. Our technique is inspired from the functionality of an auction house and has two objectives; (i) find a deployment mapping for an arbitrary application, compliant with its individual resource requirements and latency constraints, (ii) facilitate privacy, as each device participates at their own will, based on its own availability and privacy preferences. Our approach ensures seamless deployment at runtime, assuming no design-time knowledge of device resources or network topology.","Cosmin Avasalcai, Christos Tsigkanos, Schahram Dustdar",http://dx.doi.org/10.1109/edge.2019.00027,"Internet of Things, Edge Computing, Resource Management, Decentralization, Fog Computing",Decentralized Resource Auctioning for Latency-Sensitive Edge Computing
12,"Fog and Edge Computing infrastructures have been proposed to address the latency issue of the current Cloud Computing platforms. While a couple of works illustrated the advantages of these infrastructures in particular for the Internet of Things (IoT) applications, elementary Cloud services that can take advantage of the geo-distribution of resources have not been proposed yet. In this paper, we propose a first-class object store service for Fog/Edge facilities. Our proposal is built with Scale-out Network Attached Storage systems (NAS) and IPFS, a BitTorrent-based object store spread throughout the Fog/Edge infrastructure. Without impacting the IPFS advantages particularly in terms of data mobility, the use of a Scale-out NAS on each site reduces the inter-site exchanges that are costly but mandatory for the metadata management in the original IPFS implementation. Several experiments conducted on Grid'5000 testbed are analyzed and confirmed, first, the benefit of using an object store service spread at the Edge and second, the importance of mitigating inter-site accesses. The paper concludes by giving a few directions to improve the performance and fault tolerance criteria of our Fog/Edge Object Store Service.","Bastien Confais, Adrien Lebre, Beno√Æt Parrein",http://dx.doi.org/10.1109/icfec.2017.13,"Fog computing, DHT, IPFS, Scale-out NAS, RozoFS, Grid'5000",An Object Store Service for a Fog/Edge Computing Infrastructure Based on IPFS and a Scale-Out NAS
